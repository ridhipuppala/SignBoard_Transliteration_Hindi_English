{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_Transliteration_Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOI4rlrgxPI-"
      },
      "source": [
        "**Objective**\n",
        "\n",
        "1. Task at hand is creating an Encoder Decoder based Deep Neural Network for transliteration (or loosely translation) from Hindi to English.\n",
        "2. We will train a Seq2Seq Transliteration model with attention for SignBoard Tranliteration Project. \n",
        "3. Dataset used is NEWS2018\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgJlo03pxrnG",
        "outputId": "b8ef68f9-724e-4789-c6d2-d10e71718d41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GqTjeV47m4B",
        "outputId": "48b6a0b5-238d-482d-fa12-8287e4e399f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt;plt.style.use('ggplot')\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!pip install pytorch-nlp\n",
        "from torchnlp.metrics import get_moses_multi_bleu as bleu\n",
        "!rm -rf 'sample_data'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 28.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 81kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.18.5)\n",
            "Installing collected packages: pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpuvHS0mxwCd"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYrAa5laSptM"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04ZKx7Sh-J",
        "outputId": "baa65a32-2fcb-420a-c3c0-eba3a0889b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)\n",
        "\n",
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n",
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSw1SMZmx9A3"
      },
      "source": [
        "### Helper functions for data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS6ByndOxrC"
      },
      "source": [
        "#re - Regular Expressions (RegEx) rejects Python library for string processing\n",
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob3F9Dh4PChB"
      },
      "source": [
        "## Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSeoMGg0FTy"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        # return lang1_words, lang2_words\n",
        "        return lang2_words, lang1_words\n",
        "\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCCi-SerZS-",
        "outputId": "06200f52-9a40-43f9-b139-f6f5395ee0e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "train_data = TransliterationDataLoader('/content/drive/My Drive/Colab Notebooks/CapstoneProject/NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TransliterationDataLoader('/content/drive/My Drive/Colab Notebooks/CapstoneProject/NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l-iaCVdx5Ez"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjY06ghEx76b",
        "outputId": "aca5291c-49ce-4d8d-e068-bbf524b3a6e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(100):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "भाई - BHAI\n",
            "धरम - DHARAM\n",
            "हिल - HILL\n",
            "सुखदेव - SUKHDEV\n",
            "डी - D\n",
            "दोनों - DONO\n",
            "इआन - IAN\n",
            "विल्फ - WILF\n",
            "बादल - BADAL\n",
            "मॉम - MOM\n",
            "सैफुल - SAFUL\n",
            "भाई - BHAI\n",
            "वर्जीनिया - VIRGINIA\n",
            "टेलीफ़ोनिका - TELEFONICA\n",
            "हँसते - HANSTE\n",
            "इंदिरापुरम - INDIRAPURAM\n",
            "श्चेल्फी - SHELF\n",
            "एर्ने - ARNE\n",
            "ब्रूस - BRUCE\n",
            "ग्रेफ - GRAF\n",
            "स्मिता - SMITAA\n",
            "स्लोन - SLONE\n",
            "लक्ष्मीनारायण - LAXMINARAYAN\n",
            "सेंटेक्स - CENTEX\n",
            "एल्विन - ALVIN\n",
            "डैम - DAM\n",
            "गरीबी - GARIBI\n",
            "कसम - KASAM\n",
            "कुलोन - KULON\n",
            "हर - HAR\n",
            "देखो - DEKHO\n",
            "स्कूल - SCHOOL\n",
            "नेशनल - NATIONAL\n",
            "सिडोनी - SIDONIE\n",
            "मुस्तफीद - MUSTAFEED\n",
            "बॉसमन - BOSMAN\n",
            "दौलत - DAULAT\n",
            "टिम - TIM\n",
            "महल - MAHAL\n",
            "सुदीप्ता - SUDIPTA\n",
            "क़बील - QABEEL\n",
            "व्हिटब्रेड - WHITBREAD\n",
            "गोल्ड - GOLD\n",
            "बांकेबिहारी - BANKEBIHARI\n",
            "कैटिच - KATICH\n",
            "सुबर्ना - SUBARNA\n",
            "सहारा - SAHARA\n",
            "सीमा - SEEMA\n",
            "इंटरनेशनल - INTERNATIONAL\n",
            "लेक - LAKE\n",
            "सपेरा - SAPERA\n",
            "आनंदपुर - ANANDPUR\n",
            "सीवान - SIWAN\n",
            "जाम - JAM\n",
            "निरूपमा - NIRUPAMA\n",
            "मैरिस्का - MARISKA\n",
            "इंटर - INTER\n",
            "वेलाडेरो - VELADERO\n",
            "क्लिंटन - CLINTON\n",
            "गैज़ेली - GAZELLE\n",
            "कियारा - KIARA\n",
            "चिदम्बर - CHIDAMBAR\n",
            "एवलॉन - AVALON\n",
            "फोर्टालेज़ा - FORTALEZA\n",
            "सैलाब - SAILAAB\n",
            "खूनी - KHOONI\n",
            "रास्ता - RASTA\n",
            "फ़ेनस्टिन - FEINSTEIN\n",
            "प्रेरणा - PRERANA\n",
            "राम - RAM\n",
            "रोचक - ROCHAK\n",
            "अमांडा - AMANDAA\n",
            "बहू - BAHU\n",
            "मेरा - MERA\n",
            "काकाडू - KAKADU\n",
            "नगामूटू - NAGAMOOTOO\n",
            "छिहरटा - CHHIHARTA\n",
            "दलसिंह - DALSINGH\n",
            "थेम्स - THAMES\n",
            "कोबरा - COBRA\n",
            "के - KE\n",
            "जगदिप - JAGADIP\n",
            "युवराज - YUVRAJ\n",
            "रॉयल - ROYAL\n",
            "अकलमंद - AKALMAND\n",
            "ग्रेट - GREAT\n",
            "के - KE\n",
            "आफताब - AFTAB\n",
            "नोल्टे - NOLTE\n",
            "राजपाल - RAJPAL\n",
            "निघोजकर - NIGHOJKAR\n",
            "का - KA\n",
            "सिबेलियस - SIBELIUS\n",
            "धर्मानन्द - DHARMANAND\n",
            "वुड - WOOD\n",
            "रात - RAAT\n",
            "एडीडास - ADIDAS\n",
            "दीपा - DIPA\n",
            "ब्राज़विले - BRAZZAVILLE\n",
            "ऑफ - OF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpDP1_KYZIkv"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3at5C7Sy5F"
      },
      "source": [
        "def hindi_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def eng_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0] = pos\n",
        "    rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return rep"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrC3tSnm4rUk"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qagLePMjAgVF",
        "outputId": "132bd83e-94e1-4f30-b658-1ee3625709ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size) #U_attn\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size) #W_attn\n",
        "        self.attn = nn.Linear(self.hidden_size, 1) #V_attn\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs\n",
        "\n",
        "def infer(net_,inp,max_output_chars,device = 'cpu'):\n",
        "    net_.eval()\n",
        "    with torch.no_grad():\n",
        "        input = hindi_rep(inp,hindi_alpha2index).to(device)\n",
        "        out = net_.forward(input,max_output_chars)\n",
        "        return out\n",
        "\n",
        "net_attn = Transliteration_EncoderDecoder_Attention(len(hindi_alpha2index), 256, len(eng_alpha2index), verbose=True)\n",
        "out = infer(net_attn, 'सब', 30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([3, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 27])\n",
            "U * Encoder output torch.Size([3, 256])\n",
            "W * Decoder state torch.Size([3, 256])\n",
            "V torch.Size([3, 1])\n",
            "Attn torch.Size([1, 3])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 27])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyE2tSnmAW6x"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m804jsH7AXSV"
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    hindi_batch, eng_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = hindi_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        gt = eng_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            #We are retaining loss.backward to continue building the computation graph\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjto129ssrpr"
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 2000, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = (i<teacher_force_upto) ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pth')\n",
        "    torch.save(net.state_dict(), '/content/drive/My Drive/Colab Notebooks/CapstoneProject/seq2seq_attn.pth')\n",
        "    return loss_arr"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxFLBqW1Ip4v",
        "outputId": "8d59443d-3821-4226-a41e-c5ec546a87bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(hindi_alpha2index), 256, len(eng_alpha2index))\n",
        "net_attn.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/CapstoneProject/seq2seq_attn.pth'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdRpJUXNIwuv",
        "outputId": "5d900576-cc50-46d9-df34-c2036f5f6a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2500, batch_size = 256, display_freq=10, device = device_gpu)\n",
        "torch.save(net_att.state_dict(), '/content/drive/My Drive/Colab Notebooks/CapstoneProject/seq2seq_attn.pth')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 2499 Loss 0.017471330240368843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F1-FwX6YVZ"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3TWC7zhAn3z"
      },
      "source": [
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, MAX_OUTPUT_CHARS, device)\n",
        "    actual_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        actual_output_char = eng_alphabets[index+1]\n",
        "        actual_output += actual_output_char\n",
        "    print(word + ' - ' + actual_output)\n",
        "    return actual_output\n",
        "\n",
        "test(net_attn,test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8bibYl7CgX"
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    correct = 0\n",
        "    for i in range(len(test_data)):\n",
        "        hindi, english = test_data[i]\n",
        "        gt = eng_rep(english, eng_alpha2index, device)\n",
        "        outputs = infer(net, hindi, gt.shape[0], device)\n",
        "\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            eng_pos = indices.tolist()[0]\n",
        "            if eng_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy\n",
        "\n",
        "accuracy = calc_accuracy(net_att)\n",
        "print('Acurracy', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACu39Ny33JIs",
        "outputId": "db3ca90c-488b-442e-c204-933e2ee4a8d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "1/196"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00510204081632653"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBl80x-s_jpJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}